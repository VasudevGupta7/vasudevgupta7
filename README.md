### Open Source Contributions @HuggingFace

Following links to my open source contributions @ðŸ¤—'s libraries: [Transformers](https://github.com/huggingface/transformers/commits?author=vasudevgupta7), [Datasets](https://github.com/huggingface/datasets/commits?author=vasudevgupta7), [Accelerate](https://github.com/huggingface/accelerate/commits?author=vasudevgupta7), [Hub](https://github.com/huggingface/huggingface_hub/commits?author=vasudevgupta7). Below table summarizes some of my big contributions:

| Description      | Repositary     | Link   |
|------------------|----------------|--------|
| Script for training `FlaxBigBird` on natural-questions | [`ðŸ¤—Transformers`](https://github.com/huggingface/transformers) | [`#12233`](https://github.com/huggingface/transformers/pull/12233) |
| Added Flax/Jax `BigBird-RoBERTa` | [`ðŸ¤—Transformers`](https://github.com/huggingface/transformers) | [`#11967`](https://github.com/huggingface/transformers/pull/11967) |                                             
| Added PyTorch `BigBird-Pegasus` | [`ðŸ¤—Transformers`](https://github.com/huggingface/transformers) | [`#10991`](https://github.com/huggingface/transformers/pull/10991) |
| Added PyTorch `BigBird-RoBERTa` | [`ðŸ¤—Transformers`](https://github.com/huggingface/transformers) | [`#10183`](https://github.com/huggingface/transformers/pull/10183) |
| Integrated `Microsoft's DeepSpeed` with Accelerate | [`ðŸ¤—Accelerate`](https://github.com/huggingface/accelerate) | [`#82`](https://github.com/huggingface/accelerate/pull/82) |
| Added `ModelHubMixin` in Hub | [`ðŸ¤—hub`](https://github.com/huggingface/huggingface_hub) | [`#9`](https://github.com/huggingface/huggingface_hub/pull/11) |

I also wrote a blog post on **BigBird block sparse attention**. It's available in ðŸ¤—blog ([here is the link](https://huggingface.co/blog/big-bird)).

### Google Summer of Code @TensorFlow

You can find my final report [here](https://vasudevgupta7.github.io/gsoc-wav2vec2/assets/final_report). Below table is just the overview of my work:

| Description | Repository | Link |
|-------------|------------|------|
| Implement & train Wav2Vec2 model in TensorFlow | [`vasudevgupta7/gsoc-wav2vec2`](https://github.com/vasudevgupta7/gsoc-wav2vec2) | [`Commits`](https://github.com/vasudevgupta7/gsoc-wav2vec2/commits?author=vasudevgupta7) |
| Export fine-tuned Wav2Vec2 model to TFHub | [`tensorflow/tfhub.dev`](https://github.com/tensorflow/tfhub.dev) | [`#68`](https://github.com/tensorflow/tfhub.dev/pull/68) |
| Export pre-trained Wav2Vec2 model to TFHub | [`tensorflow/tfhub.dev`](https://github.com/tensorflow/tfhub.dev) | [`#65`](https://github.com/tensorflow/tfhub.dev/pull/65) |
| Add notebook for demonstrating Wav2Vec2 fine-tuning | [`tensorflow/hub`](https://github.com/tensorflow/hub) | [`#788`](https://github.com/tensorflow/hub/pull/788) |

### Personal Projects

WIP
